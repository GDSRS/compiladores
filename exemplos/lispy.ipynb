{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lispy\n",
    "\n",
    "Veja o tutorial do Peter Norvig em http://norvig.com/lispy.html. Vamos implementar\n",
    "um interpretador de Lisp/Scheme em Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import math\n",
    "import operator as op\n",
    "from collections import deque, ChainMap\n",
    "\n",
    "\n",
    "# Apelidos\n",
    "Symbol = str    # símbolo na linguagem\n",
    "Ast = list      # árvore sintática\n",
    "Ctx = ChainMap  # contexto de execução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise sintática + léxica\n",
    "\n",
    "A principal função é eval_scheme(), que analisa uma string de código e retorna a árvore sintática correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_scheme(st: str, ctx=default_context):\n",
    "    \"\"\"\n",
    "    Avalia a string de código Scheme no contexto padrão.\n",
    "    \"\"\"\n",
    "    \n",
    "    ast = parse(st)\n",
    "    return run_ast(ast, ChainMap({}, ctx))\n",
    "\n",
    "\n",
    "def parse(st: str) -> Ast:\n",
    "    \"\"\"\n",
    "    Realiza análise sintática da string de código e retorna uma \n",
    "    árvore sintática\n",
    "    \"\"\"\n",
    "    tokens = lex(st)\n",
    "    return parse_tokens(tokens)\n",
    "\n",
    "\n",
    "def lex(st: str) -> deque:\n",
    "    \"\"\"\n",
    "    Realiza a análise léxica e retorna uma lista de tokens a partir da\n",
    "    string de código.\n",
    "    \"\"\"\n",
    "    return deque(st.replace('(', ' ( ').replace(')', ' ) ').split())\n",
    "\n",
    "\n",
    "def parse_tokens(tokens: deque) -> Ast:\n",
    "    \"\"\"\n",
    "    Cria árvore sintática a partir de lista de tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    if tokens[0] == '(':\n",
    "        del tokens[0]\n",
    "        result = []\n",
    "        while tokens[0] != ')':\n",
    "            result.append(parse_tokens(tokens))\n",
    "        del tokens[0]\n",
    "        return result\n",
    "    \n",
    "    try:\n",
    "        result = float(tokens[0])\n",
    "        del tokens[0]\n",
    "        return result\n",
    "    except ValueError:\n",
    "        return tokens.popleft()\n",
    "    \n",
    "    \n",
    "# Contexto de execução\n",
    "default_context = {\n",
    "    '+': op.add,\n",
    "    '-': op.sub,\n",
    "    '*': op.mul,\n",
    "    '/': op.truediv,\n",
    "    '<': op.lt,\n",
    "    '<=': op.le,\n",
    "    'sqrt': math.sqrt,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretador\n",
    "\n",
    "O interpretador consiste em uma única função que recebe uma árvore sintática e executa os comandos correspondentes no contexto dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ast(ast: Ast, ctx: Ctx):\n",
    "    \"\"\"\n",
    "    Executa árvore sintática no contexto de execução dada.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(ast, (float, int)):\n",
    "        return ast\n",
    "    elif isinstance(ast, Symbol):\n",
    "        try:\n",
    "            return ctx[ast]\n",
    "        except KeyError:\n",
    "            raise NameError(f'unknown variable: {ast}')\n",
    "    \n",
    "    head, *args = ast\n",
    "    if head == 'define':\n",
    "        name, value = args\n",
    "        ctx[name] = result = run_ast(value, ctx)\n",
    "        return result\n",
    "\n",
    "    elif head == 'if':\n",
    "        cond, true, false = args\n",
    "        cond = run_ast(cond, ctx)\n",
    "        if cond:\n",
    "            return run_ast(true, ctx)\n",
    "        else:\n",
    "            return run_ast(false, ctx)\n",
    "        \n",
    "    elif head == 'lambda':\n",
    "        arg_names, body = args\n",
    "        \n",
    "        def function(*arg_values):\n",
    "            local = dict(zip(arg_names, arg_values))\n",
    "            new_ctx = ChainMap(local, ctx)\n",
    "            return run_ast(body, new_ctx)\n",
    "        return function\n",
    "    \n",
    "    else:\n",
    "        func = run_ast(head, ctx)\n",
    "        args = [run_ast(arg, ctx) for arg in args]\n",
    "        return func(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Exemplos\n",
    "#\n",
    "scheme_factorial = '''\n",
    "(define fat (lambda (n) \n",
    "    (if (< n 2) \n",
    "        1\n",
    "        (* n (fat (- n 1))))))\n",
    "'''\n",
    "\n",
    "fat = eval_scheme(scheme_factorial)\n",
    "fat(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
